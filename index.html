<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Bitwise-nn-fpga by tdrussell</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Bitwise-nn-fpga</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.com/tdrussell/bitwise-nn-fpga" class="btn">View on GitHub</a>
      <a href="https://github.com/tdrussell/bitwise-nn-fpga/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/tdrussell/bitwise-nn-fpga/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h3>
<a id="fpga-implementation-of-bitwise-neural-networks" class="anchor" href="#fpga-implementation-of-bitwise-neural-networks" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>FPGA Implementation of Bitwise Neural Networks</h3>

<p>Trace Russell</p>

<h3>
<a id="project-proposal" class="anchor" href="#project-proposal" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Project Proposal</h3>

<p>This project will consist of an FPGA-based implementation of bitwise neural networks. I currently plan on implementing the system on a Xilinx Zynq-7000 FPGA. </p>

<h1>
<a id="background" class="anchor" href="#background" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Background:</h1>

<p>A bitwise neural network is a neural network where all the weights and activations are binary values. A forward pass through the network consists only of bitwise operations and bit counting. As a result, it is possible to efficiently implement these types of networks on an FPGA, because there is no need for expensive multiply operations.</p>

<p>The FPGA hardware naturally gives many opportunities to exploit parallelism in order to speed up forward passes through the neural network. For instance, and obvious parallelization opportunity is to compute an single neuron's weight 'multiplications' (actually bitwise operations) in parallel. There may also be chances to compute multiple neuron activations in parallel. Furthermore, adding up the results of weight multiplications might be done with a parallel logarithmic adder tree.</p>

<h1>
<a id="the-challenge" class="anchor" href="#the-challenge" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>The Challenge:</h1>

<p>This project has many key challenges. The main overarching challenge is how to efficiently represent the bitwise neural network on the FPGA. The key point here is where the weights will be stored. For small networks, it might be possible to store the network weights in block RAM on the FPGA itself. Larger networks might require storing the weights in main system RAM, and streaming them in during a forward pass along with the input data itself. Both of these options will need to be explored.</p>

<h1>
<a id="resources" class="anchor" href="#resources" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Resources:</h1>

<p>As mentioned above, I currently plan on using a Xilinx Zynq-7000 based FPGA development board for the implementation, though this might change as I more thoroughly research hardware options. The Zync SoC has an integrated ARM processor, and I believe this can make the implementation simpler in some ways. For instance, I can use the embedded Linux running on the ARM processor to manage allocating memory in main RAM, and offload a forward pass of an example through the network to the FPGA.</p>

<p>The main goal of this project is implementing an FPGA architecture for running bitwise neural networks, rather than the design of software that allows training those bitwise networks. Luckily, the authors of [1] have released their research software that allows training and running binarized neural networks on CPUs and GPUs. One of their implementations is for the Torch7 scientific computing framework, which I am already well familiar with. As such, it should not be difficult for me to use this software to train a bitwise neural network whose implementation I will develop on the FPGA.</p>

<h1>
<a id="goals-and-deliverables" class="anchor" href="#goals-and-deliverables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Goals and Deliverables</h1>

<p>To be added.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/tdrussell/bitwise-nn-fpga">Bitwise-nn-fpga</a> is maintained by <a href="https://github.com/tdrussell">tdrussell</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
